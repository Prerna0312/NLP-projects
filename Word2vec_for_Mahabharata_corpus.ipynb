{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPOdKTG0US9t"
      },
      "source": [
        "### Learning Objectives:\n",
        "\n",
        "At the end of the experiment, you will be able to:\n",
        "\n",
        "* understand word2vec in action."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDTJ3UXdUS9v"
      },
      "source": [
        "In this experiment we will use **Mahabharata** as our text corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STSgFQWikdwI"
      },
      "source": [
        "## Setup Steps"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget 'https://cdn.talentsprint.com/aiml/Experiment_related_data/week1/Saturday_Experiment/MB.txt'\n",
        "!wget 'https://cdn.talentsprint.com/aiml/Experiment_related_data/week1/Saturday_Experiment/word2vec.png'"
      ],
      "metadata": {
        "id": "IDn77M7BhhlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL95z915CeZh"
      },
      "source": [
        "### Import required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qd6Z7aW0qmgX"
      },
      "source": [
        "# Import nltk package\n",
        "import nltk\n",
        "\n",
        "# Download wordnet from NLTK to perform Stemmer\n",
        "nltk.download(\"wordnet\")\n",
        "\n",
        "# Python library for Vector space modeling and topic modeling\n",
        "import gensim\n",
        "\n",
        "# Regular Expression\n",
        "import re\n",
        "\n",
        "# Basic Python Packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnSw4jIMw2Y1"
      },
      "source": [
        "### Pre-Processing and Develop Word Embeddings\n",
        "\n",
        "* Load the Mahabharata corpus\n",
        "* Perform Stemming and removing the stop words\n",
        "* Generate word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eMXInB-2gUSL"
      },
      "source": [
        "# Stemmer with Python nltk package\n",
        "stemmer = nltk.PorterStemmer()\n",
        "\n",
        "# Download all the stopwords from the NLTK package using nltk.download('stopwords')\n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "stopWords = set(stopwords.words(\"english\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzDazox-frQe"
      },
      "source": [
        "MB_words = []\n",
        "\n",
        "# Open the text file in read mode\n",
        "with open(\"MB.txt\", \"r\") as file:\n",
        "\n",
        "   # Store each line in the file as a separate element in a list\n",
        "   lines = file.readlines()\n",
        "\n",
        "   # Take each line from the list of lines and collect all the words\n",
        "   for line in lines:\n",
        "      # findall() function returns a list containing all matches between a-z\n",
        "      words = re.findall(r\"(\\b[a-z][a-z]*\\b)\", line.lower())\n",
        "\n",
        "      # Stemming each word in to a list, if the word is not in stopwords\n",
        "      words = [stemmer.stem(word) for word in words if word not in stopWords]\n",
        "\n",
        "      MB_words.append(words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(MB_words)"
      ],
      "metadata": {
        "id": "gKfEsZL4ORmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MB_words"
      ],
      "metadata": {
        "id": "gDFXLwSSOhfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0z39MeFLGJ-d"
      },
      "source": [
        "Get the vocabulary and vectors using gensim package.\n",
        "\n",
        "**min_count** ignore words that appear less than the specified count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg3z8-NQola3"
      },
      "source": [
        "# Train the gensim model on the MB_words\n",
        "model = gensim.models.Word2Vec(MB_words, min_count=120)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "id": "BQ7FYvioiUsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eDzmJnnKiPM"
      },
      "source": [
        "# Total number of words in the trained model\n",
        "print(\"Total number of words in the trained model: \", len(model.wv.index_to_key))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.index_to_key[2]"
      ],
      "metadata": {
        "id": "JR4BXKB6xEHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.key_to_index"
      ],
      "metadata": {
        "id": "J63JFKyOwGG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a_RF-5WLn_Z"
      },
      "source": [
        "# Number of vectors generated for each word\n",
        "print(\"Dimensionality of word embeddings: \", len(model.wv.vectors[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.vectors.shape"
      ],
      "metadata": {
        "id": "xudOVBuGRmrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HrlBP5AtSsR"
      },
      "source": [
        "### Construct the word and vector list by iterating through the vocabulary of the pretrained word2vec model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_xS-MhisKw7"
      },
      "source": [
        "words_list = []\n",
        "vector_list = []\n",
        "\n",
        "for i,word in enumerate(model.wv.index_to_key):\n",
        "    try :\n",
        "        words_list.append(word)\n",
        "        vector_list.append(model.wv.vectors[i])  # append(model[i])\n",
        "    except :\n",
        "        pass\n",
        "\n",
        "words_list = np.array(words_list)\n",
        "vector_list = np.array(vector_list)\n",
        "\n",
        "print(words_list.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_list"
      ],
      "metadata": {
        "id": "c4L2gdozSH0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_list.shape"
      ],
      "metadata": {
        "id": "cl0Asf5JSo-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_list[1]"
      ],
      "metadata": {
        "id": "uUmCBw0Jypzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPCOgxJjUS-w"
      },
      "source": [
        "### Visualization and Plotting the reduced Word2Vec representation\n",
        "\n",
        "* As vector_list dimensions are huge, reduce the dimensions of the vectors to 2D using PCA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nu7hGg94s9IX"
      },
      "source": [
        "# Check the shape of the vector_list before reducing its dimensions\n",
        "print(\"Shape of the vectors_list before reducing the dimensions: \", vector_list.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NfDieGYMmAe"
      },
      "source": [
        "* Applying PCA to reduce the dimensions of the vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3NQ4_aStB1k"
      },
      "source": [
        "# Create a 2-dimensional PCA model of the word vectors using the scikit-learn PCA class\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# n_components in PCA specifies the no.of dimensions\n",
        "pca = PCA(n_components=2)\n",
        "\n",
        "# Fit and transform the vectors using PCA model\n",
        "reduced_vector = pca.fit_transform(vector_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "spd_K0-BuAj6"
      },
      "source": [
        "# Check the shape of the reduced_vector after reducing its dimensions\n",
        "print(\"Shape of the vectors_list after reducing the dimensions to 2D: \", reduced_vector.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfznW8tgRkiH"
      },
      "source": [
        "* Visualize the reduced Word2Vec representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0G1YmkAKQ5he"
      },
      "source": [
        "colors = [\"green\" for i in range(len(reduced_vector))]\n",
        "\n",
        "x = []\n",
        "y = []\n",
        "for vec in reduced_vector:\n",
        "    x.append(vec[0])\n",
        "    y.append(vec[1])\n",
        "\n",
        "plt.figure(figsize=(28,20))\n",
        "for i in range(len(words_list)):\n",
        "    plt.scatter(x[i],y[i], color=colors[i])\n",
        "    plt.annotate(words_list[i], xy=(x[i], y[i]))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-v2yVWouGM2"
      },
      "source": [
        "### Choose few characters from Mahabharata and find the similar characters\n",
        "\n",
        "* Find the location of the chosen characters in word_list\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Megx8-C0uFJ1"
      },
      "source": [
        "MB_characters = ['krishna', 'arjuna', 'pandu', 'bhima', 'sakuni', 'duryodhana', 'bhishma', 'kunti', 'karna', 'madri', 'nakula', 'sahadeva', 'draupadi']\n",
        "\n",
        "# Get the location of MB_characters from the words_list\n",
        "locs = [np.where(words_list == x)[0][0] for x in MB_characters]\n",
        "\n",
        "print(\"The location of the selected characters \\n\", locs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohI96wuYN_F7"
      },
      "source": [
        "* Visualization of the chosen characters in the Mahabharata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.wv.key_to_index['krishna']"
      ],
      "metadata": {
        "id": "MZ5sQ8Puz3mo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8En0XkSSuagA"
      },
      "source": [
        "# Generating the vectors for chosen characters and reducing the dimensions using PCA to plot in 2-D plane\n",
        "\n",
        "fig = plt.figure(figsize=(14,6))\n",
        "ax = fig.add_subplot(111)\n",
        "for character, pos in zip(MB_characters, locs):\n",
        "  print(character)\n",
        "  char_v = vector_list[pos]\n",
        "  # 'char_v' contains the vector representation of each character\n",
        "  # Adding one more dimension to the 'char_v', while PCA allows only 2-d array\n",
        "  # Converting it back to 1-d array to plot the transformed vector\n",
        "  value = pca.transform([char_v])[0]\n",
        "  ax.plot(value[0], value[1],  \"r*\")\n",
        "  plt.annotate(words_list[pos], xy=value, xytext=value+0.01)\n",
        "\n",
        "plt.show()\n",
        "fig.savefig('word2vec.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_vVIRCiu9_Y"
      },
      "source": [
        "* Find the top-5 similar characters for the selected characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRQEkPQWu9Qf"
      },
      "source": [
        "names= []\n",
        "for character in MB_characters:\n",
        "    near = model.wv.most_similar(character, topn = 5)\n",
        "    nearNames = [x[0] for x in near]\n",
        "    names.append(nearNames)\n",
        "\n",
        "pd.DataFrame(names,columns=['Similarity_1','Similarity_2','Similarity_3','Similarity_4','Similarity_5'], index = MB_characters)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}